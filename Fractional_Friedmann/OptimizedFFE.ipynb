{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84dddc4",
   "metadata": {},
   "source": [
    "The Fractional Friedmann Equation:\n",
    " \n",
    "$$ {}^{C}D^{\\alpha}_{t}a(t) = \\tau_{0}^{\\alpha-1} H_{0} \\left[\\sum_{i}\\Omega_{i}\\left(\\frac{a_{0}}{a(t)}\\right)^{3(1+w_{i})}\\right]^{1/2} a(t) $$\n",
    " \n",
    "where:\n",
    "- $0 < \\alpha \\leq 1$ is the fractional order\n",
    "- $\\tau_0$ is a characteristic time scale (typically $1/H_0$)\n",
    "- $\\Omega_i$ are density parameters for different components (matter, dark energy, radiation)\n",
    "- $w_i$ are equation of state parameters\n",
    "Gaussian Initial Conditions\n",
    "$$ a(t) = a_0 \\exp\\left(-\\frac{(t-t_0)^2}{2\\sigma^2}\\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78aadb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, float64, int64\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42cd6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def compute_weights_vectorized(n, alpha, gamma_inv):\n",
    "    if n == 0:\n",
    "        return np.array([gamma_inv], dtype=np.float64)\n",
    "    \n",
    "    j = np.arange(1, n + 1)\n",
    "    weights = ((n + 1 - j)**alpha - (n - j)**alpha) * gamma_inv\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80107846",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def exponential_time_scheme(a, H0, Omega_m, Omega_r, t, \n",
    "                           min_dt=1e-12, max_dt=1e-6, safety=0.1):\n",
    "    # Compute Hubble parameter at current scale factor\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    H = H0 * np.sqrt(Omega_m * a**-3 + Omega_r * a**-4 + Omega_de)\n",
    "    \n",
    "    # Base time step: inverse of Hubble rate (characteristic timescale)\n",
    "    dt_base = safety / H if H > 0 else max_dt\n",
    "    \n",
    "    # Exponential scaling: smaller steps early, larger steps late\n",
    "    if a < 1e-4:\n",
    "        # Radiation era: very small steps\n",
    "        dt = dt_base * 0.01\n",
    "    elif a < 1e-3:\n",
    "        dt = dt_base * 0.05\n",
    "    elif a < 1e-2:\n",
    "        dt = dt_base * 0.1\n",
    "    elif a < 0.1:\n",
    "        dt = dt_base * 0.2\n",
    "    elif a < 0.5:\n",
    "        dt = dt_base * 0.5\n",
    "    else:\n",
    "        dt = dt_base * 1.0\n",
    "    \n",
    "    # Clip to bounds\n",
    "    if dt < min_dt:\n",
    "        dt = min_dt\n",
    "    elif dt > max_dt:\n",
    "        dt = max_dt\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03625f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit([\n",
    "    float64[:](int64, float64, float64),  \n",
    "], cache=True, fastmath=True)\n",
    "def compute_all_weights(n, alpha, gamma_inv):\n",
    "    if n == 0:\n",
    "        return np.array([gamma_inv], dtype=np.float64)\n",
    "    \n",
    "    j = np.arange(1, n + 1)\n",
    "    # Use exp/log for better numerical stability with small alpha\n",
    "    weights = np.empty_like(j, dtype=np.float64)\n",
    "    \n",
    "    for i in range(len(j)):\n",
    "        ji = j[i]\n",
    "        term1 = np.exp(alpha * np.log(n + 1 - ji))\n",
    "        term2 = np.exp(alpha * np.log(n - ji))\n",
    "        weights[i] = (term1 - term2) * gamma_inv\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8994d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def compute_f(a, H0, Omega_m, Omega_r):\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "\n",
    "    return H0 * a * np.sqrt(Omega_m * a**-3 +  Omega_r * a**-4 +  Omega_de )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0c72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def numba_gamma(x):\n",
    "    \"\"\"Numba-compatible gamma function using math.gamma\"\"\"\n",
    "    return math.gamma(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4746d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def solve_fractional_optimized(\n",
    "    alpha=1.0, \n",
    "    H0=1.0, \n",
    "    Omega_m=0.315, \n",
    "    Omega_r=9.2e-5, \n",
    "    a_start=1e-6, \n",
    "    a_end=1.0,\n",
    "    min_dt=1e-12, \n",
    "    max_dt=1e-6, \n",
    "    safety=0.1,\n",
    "    max_iterations=100000,  # Now supports 1M iterations\n",
    "    store_every=100,         # Store only every nth point\n",
    "    use_exponential_stepping=True,  # Use new adaptive scheme\n",
    "    tolerance=1e-8           # Convergence tolerance\n",
    "):\n",
    "    # Precompute constants\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    \n",
    "    # Use Numba-compatible gamma function\n",
    "    gamma_inv = 1.0 / numba_gamma(alpha + 1)\n",
    "    \n",
    "    # Initialize arrays with pre-allocated memory\n",
    "    # We'll resize as needed, but start with reasonable size\n",
    "    initial_capacity = min(max_iterations // store_every + 1000, 100000)\n",
    "    t_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    a_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    \n",
    "    # Initialize current state\n",
    "    t = 0.0\n",
    "    a = a_start\n",
    "    \n",
    "    # Store initial values\n",
    "    t_array[0] = t\n",
    "    a_array[0] = a\n",
    "    \n",
    "    # Store ALL f(a) values (full history for accuracy)\n",
    "    # We'll use Python list for dynamic growth inside Numba\n",
    "    f_current = compute_f(a, H0, Omega_m, Omega_r)\n",
    "    f_list = [f_current]\n",
    "    \n",
    "    # For tracking when a=1\n",
    "    t_present = -1.0\n",
    "    found_present = False\n",
    "    store_idx = 1\n",
    "    iteration = 0\n",
    "    \n",
    "    # Main integration loop\n",
    "    while a < a_end and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Choose time stepping scheme\n",
    "        if use_exponential_stepping:\n",
    "            dt = exponential_time_scheme(a, H0, Omega_m, Omega_r, t, \n",
    "                                        min_dt, max_dt, safety)\n",
    "        else:\n",
    "            # Original adaptive scheme as fallback\n",
    "            if a < 1e-4:\n",
    "                dt = safety * a * a / (H0 * np.sqrt(Omega_r))\n",
    "            else:\n",
    "                dt = safety * np.sqrt(a * a * a) / (H0 * np.sqrt(Omega_m))\n",
    "            \n",
    "            if dt < min_dt:\n",
    "                dt = min_dt\n",
    "            elif dt > max_dt:\n",
    "                dt = max_dt\n",
    "        \n",
    "        # Compute fractional sum over full history\n",
    "        n = iteration - 1  # Number of previous points\n",
    "        \n",
    "        if n == 0:\n",
    "            # First step: simple formula\n",
    "            sum_term = f_list[0] * gamma_inv\n",
    "        else:\n",
    "            # For large n, we need to be smart about memory\n",
    "            if n > 100000:\n",
    "                # For very large n, compute weights in chunks\n",
    "                sum_term = 0.0\n",
    "                chunk_size = 10000\n",
    "                \n",
    "                for chunk_start in range(0, n, chunk_size):\n",
    "                    chunk_end = min(chunk_start + chunk_size, n)\n",
    "                    j_chunk = np.arange(chunk_start + 1, chunk_end + 1)\n",
    "                    \n",
    "                    # Vectorized computation for this chunk\n",
    "                    weights_chunk = ((n + 1 - j_chunk)**alpha - (n - j_chunk)**alpha) * gamma_inv\n",
    "                    \n",
    "                    # Get corresponding f values\n",
    "                    f_chunk = np.array(f_list[chunk_start:chunk_end], dtype=np.float64)\n",
    "                    \n",
    "                    # Add to sum\n",
    "                    sum_term += np.dot(weights_chunk, f_chunk)\n",
    "            else:\n",
    "                # For moderate n, compute all weights at once\n",
    "                weights = compute_all_weights(n, alpha, gamma_inv)\n",
    "                f_values = np.array(f_list[:n], dtype=np.float64)\n",
    "                sum_term = np.dot(weights, f_values)\n",
    "        \n",
    "        # Update scale factor\n",
    "        dt_alpha = dt**alpha\n",
    "        a_new = a_start + dt_alpha * sum_term\n",
    "        \n",
    "        # Ensure positivity and check convergence\n",
    "        a_new = max(a_new, 1e-30)\n",
    "        \n",
    "        # Check for significant change\n",
    "        if abs(a_new - a) / max(abs(a), 1e-10) < tolerance and iteration > 10:\n",
    "            # Convergence reached\n",
    "            break\n",
    "        \n",
    "        a = a_new\n",
    "        t += dt\n",
    "        \n",
    "        # Check if we've reached a=1\n",
    "        if not found_present and a >= 1.0:\n",
    "            t_present = t\n",
    "            found_present = True\n",
    "        \n",
    "        # Store f(a) for next iteration\n",
    "        f_current = compute_f(a, H0, Omega_m, Omega_r)\n",
    "        f_list.append(f_current)\n",
    "        \n",
    "        # Store results (thinned)\n",
    "        if iteration % store_every == 0:\n",
    "            # Resize arrays if needed\n",
    "            if store_idx >= len(t_array):\n",
    "                new_capacity = min(len(t_array) * 2, max_iterations // store_every + 10000)\n",
    "                t_array = np.concatenate([\n",
    "                    t_array, \n",
    "                    np.zeros(new_capacity - len(t_array), dtype=np.float64)\n",
    "                ])\n",
    "                a_array = np.concatenate([\n",
    "                    a_array,\n",
    "                    np.zeros(new_capacity - len(a_array), dtype=np.float64)\n",
    "                ])\n",
    "            \n",
    "            t_array[store_idx] = t\n",
    "            a_array[store_idx] = a\n",
    "            store_idx += 1\n",
    "    \n",
    "    # Trim arrays to actual size\n",
    "    t_array = t_array[:store_idx]\n",
    "    a_array = a_array[:store_idx]\n",
    "    \n",
    "    # If never reached a=1, find closest\n",
    "    if not found_present and len(a_array) > 0:\n",
    "        idx_closest = np.argmin(np.abs(a_array - 1.0))\n",
    "        t_present = t_array[idx_closest]\n",
    "    \n",
    "    return t_array, a_array, t_present, iteration\n",
    "\n",
    "# Alternative: If you need scipy.special.gamma for complex arguments,\n",
    "# you can use this approach:\n",
    "\n",
    "# First, compile a simple version without the gamma function\n",
    "@njit(cache=True, fastmath=True)\n",
    "def solve_fractional_simple(\n",
    "    alpha=1.0, \n",
    "    H0=1.0, \n",
    "    Omega_m=0.315, \n",
    "    Omega_r=9.2e-5, \n",
    "    a_start=1e-6, \n",
    "    a_end=1.0,\n",
    "    max_iterations=50000,\n",
    "    store_every=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Simplified version that doesn't use scipy.special.gamma\n",
    "    \"\"\"\n",
    "    # Use math.gamma which is Numba-compatible\n",
    "    gamma_inv = 1.0 / math.gamma(alpha + 1)\n",
    "    \n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    \n",
    "    # Initialize arrays\n",
    "    t_list = [0.0]\n",
    "    a_list = [a_start]\n",
    "    \n",
    "    t = 0.0\n",
    "    a = a_start\n",
    "    \n",
    "    # Store f values\n",
    "    f_list = [H0 * a * np.sqrt(Omega_m * a**-3 + Omega_r * a**-4 + Omega_de)]\n",
    "    \n",
    "    t_present = -1.0\n",
    "    found_present = False\n",
    "    \n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        if a >= a_end:\n",
    "            break\n",
    "        \n",
    "        # Simple time stepping\n",
    "        if a < 1e-4:\n",
    "            dt = 0.1 * a**2 / (H0 * np.sqrt(Omega_r))\n",
    "        else:\n",
    "            dt = 0.1 * np.sqrt(a**3) / (H0 * np.sqrt(Omega_m))\n",
    "        \n",
    "        dt = min(max(dt, 1e-12), 1e-6)\n",
    "        \n",
    "        # Compute fractional sum\n",
    "        n = iteration - 1\n",
    "        \n",
    "        if n == 0:\n",
    "            sum_term = f_list[0] * gamma_inv\n",
    "        else:\n",
    "            # Vectorized computation\n",
    "            j = np.arange(1, n + 1)\n",
    "            weights = ((n + 1 - j)**alpha - (n - j)**alpha) * gamma_inv\n",
    "            f_vals = np.array(f_list[:n], dtype=np.float64)\n",
    "            sum_term = np.dot(weights, f_vals)\n",
    "        \n",
    "        # Update a\n",
    "        a = a_start + (dt**alpha) * sum_term\n",
    "        t += dt\n",
    "        \n",
    "        # Check present epoch\n",
    "        if not found_present and a >= 1.0:\n",
    "            t_present = t\n",
    "            found_present = True\n",
    "        \n",
    "        # Store f(a)\n",
    "        f_list.append(H0 * a * np.sqrt(Omega_m * a**-3 + Omega_r * a**-4 + Omega_de))\n",
    "        \n",
    "        # Store results\n",
    "        if iteration % store_every == 0:\n",
    "            t_list.append(t)\n",
    "            a_list.append(a)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    t_array = np.array(t_list, dtype=np.float64)\n",
    "    a_array = np.array(a_list, dtype=np.float64)\n",
    "    \n",
    "    if not found_present and len(a_array) > 0:\n",
    "        idx_closest = np.argmin(np.abs(a_array - 1.0))\n",
    "        t_present = t_array[idx_closest]\n",
    "    \n",
    "    return t_array, a_array, t_present, iteration\n",
    "\n",
    "# Quick test function\n",
    "def quick_test(alpha=0.9, iterations=10000):\n",
    "    \"\"\"Quick test of the solver\"\"\"\n",
    "    print(f\"Quick test with α={alpha}, max_iterations={iterations}\")\n",
    "    \n",
    "    # Use the simple version for testing\n",
    "    t_array, a_array, t_present, actual_iters = solve_fractional_simple(\n",
    "        alpha=alpha,\n",
    "        max_iterations=iterations,\n",
    "        store_every=10\n",
    "    )\n",
    "    \n",
    "    print(f\"Completed {actual_iters} iterations\")\n",
    "    print(f\"Present time (a=1): {t_present:.4f} H₀⁻¹\")\n",
    "    print(f\"Final a: {a_array[-1]:.6f}\")\n",
    "    print(f\"Time range: {t_array[0]:.2e} to {t_array[-1]:.4f}\")\n",
    "    print(f\"Points stored: {len(t_array)}\")\n",
    "    \n",
    "    return t_array, a_array\n",
    "\n",
    "# Test function for the optimized version (may need to run twice for compilation)\n",
    "def test_optimized():\n",
    "    \"\"\"Test the optimized version\"\"\"\n",
    "    print(\"Testing optimized fractional solver...\")\n",
    "    \n",
    "    # First run will compile\n",
    "    print(\"First run (compilation)...\")\n",
    "    t1, a1, tp1, it1 = solve_fractional_optimized(\n",
    "        alpha=1,\n",
    "        max_iterations=1000,\n",
    "        store_every=10\n",
    "    )\n",
    "    \n",
    "    print(f\"First run: {it1} iterations, t_present={tp1:.4f}\")\n",
    "    \n",
    "    # Second run should use cache\n",
    "    print(\"\\nSecond run (cached)...\")\n",
    "    t2, a2, tp2, it2 = solve_fractional_optimized(\n",
    "        alpha=1,\n",
    "        max_iterations=1000,\n",
    "        store_every=10\n",
    "    )\n",
    "    \n",
    "    print(f\"Second run: {it2} iterations, t_present={tp2:.4f}\")\n",
    "    \n",
    "    return t1, a1, t2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "806f5a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test with α=1, max_iterations=100000\n",
      "Completed 100000 iterations\n",
      "Present time (a=1): 0.1000 H₀⁻¹\n",
      "Final a: 0.211997\n",
      "Time range: 0.00e+00 to 0.1000\n",
      "Points stored: 10001\n"
     ]
    }
   ],
   "source": [
    "t_simple, a_simple = quick_test(alpha=1, iterations=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043f1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to physical time (s)\n",
    "H0_physical = 2.19e-18  # s⁻¹\n",
    "seconds_per_year = 365.25 * 24 * 3600\n",
    "seconds_per_Gyr = seconds_per_year * 1e9\n",
    "\n",
    "# Time from Big Bang in s\n",
    "t_s = t_simple / H0_physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c543c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31c306ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ticks = [1e1,1e3,1e5,1e7,1e9,1e11,1e13,1e15,1e17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f2f8ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(a_simple,t_s)\n",
    "plt.xlabel(r\"Scale factor a\")\n",
    "plt.ylabel(r\"Cosmic time (sec)\")\n",
    "plt.title(\"Friedmann Equation\\n$ a(0)=10^{-6}$\")\n",
    "plt.yticks(y_ticks)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57efafa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_simple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b84d54b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09997001453927488"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_simple[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee798ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007482512075182797"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_simple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e4b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_simple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d92d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick test\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fractional Cosmology Solver - Numba Optimized\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test the simple version first\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Now testing optimized version (may take a moment to compile)...\")\n",
    "    \n",
    "    # Test the optimized version\n",
    "    try:\n",
    "        \n",
    "        print(\"\\nBoth versions working correctly!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOptimized version error: {e}\")\n",
    "        print(\"Using simple version instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842aebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2047417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, float64, int64\n",
    "from scipy.special import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d86ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit([\n",
    "    float64[:](int64, float64, float64),  # Signature for better compilation\n",
    "], cache=True, fastmath=True)\n",
    "def compute_all_weights(n, alpha, gamma_inv):\n",
    "    if n == 0:\n",
    "        return np.array([gamma_inv], dtype=np.float64)\n",
    "    \n",
    "    j = np.arange(1, n + 1)\n",
    "    # Use exp/log for better numerical stability with small alpha\n",
    "    weights = np.empty_like(j, dtype=np.float64)\n",
    "    \n",
    "    for i in range(len(j)):\n",
    "        ji = j[i]\n",
    "        term1 = np.exp(alpha * np.log(n + 1 - ji))\n",
    "        term2 = np.exp(alpha * np.log(n - ji))\n",
    "        weights[i] = (term1 - term2) * gamma_inv\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b793dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def exponential_time_scheme(a, H0, Omega_m, Omega_r, t, \n",
    "                           min_dt=1e-12, max_dt=1e-6, safety=0.1):\n",
    "\n",
    "    # Compute Hubble parameter at current scale factor\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    H = H0 * np.sqrt(Omega_m * a**-3 + Omega_r * a**-4 + Omega_de)\n",
    "    \n",
    "    # Base time step: inverse of Hubble rate (characteristic timescale)\n",
    "    dt_base = safety / H if H > 0 else max_dt\n",
    "    \n",
    "    # Exponential scaling: smaller steps early, larger steps late\n",
    "    if a < 1e-4:\n",
    "        # Radiation era: very small steps\n",
    "        dt = dt_base * 0.01\n",
    "    elif a < 1e-3:\n",
    "        dt = dt_base * 0.05\n",
    "    elif a < 1e-2:\n",
    "        dt = dt_base * 0.1\n",
    "    elif a < 0.1:\n",
    "        dt = dt_base * 0.2\n",
    "    elif a < 0.5:\n",
    "        dt = dt_base * 0.5\n",
    "    else:\n",
    "        dt = dt_base * 1.0\n",
    "    \n",
    "    # Clip to bounds\n",
    "    if dt < min_dt:\n",
    "        dt = min_dt\n",
    "    elif dt > max_dt:\n",
    "        dt = max_dt\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71ea219",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def compute_f(a, H0, Omega_m, Omega_r):\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "\n",
    "    return H0 * a * np.sqrt(Omega_m * a**-3 +  Omega_r * a**-4 +  Omega_de )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062d1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def solve_fractional_optimized(\n",
    "    alpha=1.0, \n",
    "    H0=1.0, \n",
    "    Omega_m=0.315, \n",
    "    Omega_r=9.2e-5, \n",
    "    a_start=1e-6, \n",
    "    a_end=1.0,\n",
    "    min_dt=1e-12, \n",
    "    max_dt=1e-6, \n",
    "    safety=0.1,\n",
    "    max_iterations=10000,  # Now supports 1M iterations\n",
    "    store_every=100,         # Store only every nth point\n",
    "    use_exponential_stepping=True,  # Use new adaptive scheme\n",
    "    tolerance=1e-8           # Convergence tolerance\n",
    "):\n",
    "\n",
    "    # Precompute constants\n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    gamma_inv = 1.0 / gamma(alpha + 1)\n",
    "    \n",
    "    # Initialize arrays with pre-allocated memory\n",
    "    # We'll resize as needed, but start with reasonable size\n",
    "    initial_capacity = min(max_iterations // store_every + 1000, 100000)\n",
    "    t_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    a_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    \n",
    "    # Initialize current state\n",
    "    t = 0.0\n",
    "    a = a_start\n",
    "    \n",
    "    # Store initial values\n",
    "    t_array[0] = t\n",
    "    a_array[0] = a\n",
    "    \n",
    "    # Store ALL f(a) values (full history for accuracy)\n",
    "    # We'll use Python list for dynamic growth inside Numba\n",
    "    f_list = [compute_f(a, H0, Omega_m, Omega_r)]\n",
    "    \n",
    "    # For tracking when a=1\n",
    "    t_present = -1.0\n",
    "    found_present = False\n",
    "    store_idx = 1\n",
    "    iteration = 0\n",
    "    \n",
    "    # Main integration loop\n",
    "    while a < a_end and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Choose time stepping scheme\n",
    "        if use_exponential_stepping:\n",
    "            dt = exponential_time_scheme(a, H0, Omega_m, Omega_r, t, \n",
    "                                        min_dt, max_dt, safety)\n",
    "        else:\n",
    "            # Original adaptive scheme as fallback\n",
    "            if a < 1e-4:\n",
    "                dt = safety * a * a / (H0 * np.sqrt(Omega_r))\n",
    "            else:\n",
    "                dt = safety * np.sqrt(a * a * a) / (H0 * np.sqrt(Omega_m))\n",
    "            \n",
    "            if dt < min_dt:\n",
    "                dt = min_dt\n",
    "            elif dt > max_dt:\n",
    "                dt = max_dt\n",
    "        \n",
    "        # Compute fractional sum over full history\n",
    "        n = iteration - 1  # Number of previous points\n",
    "        \n",
    "        if n == 0:\n",
    "            # First step: simple formula\n",
    "            sum_term = f_list[0] * gamma_inv\n",
    "        else:\n",
    "            # For large n, we need to be smart about memory\n",
    "            if n > 100000:\n",
    "                # For very large n, compute weights in chunks\n",
    "                sum_term = 0.0\n",
    "                chunk_size = 10000\n",
    "                \n",
    "                for chunk_start in range(0, n, chunk_size):\n",
    "                    chunk_end = min(chunk_start + chunk_size, n)\n",
    "                    j_chunk = np.arange(chunk_start + 1, chunk_end + 1)\n",
    "                    \n",
    "                    # Vectorized computation for this chunk\n",
    "                    weights_chunk = ((n + 1 - j_chunk)**alpha - (n - j_chunk)**alpha) * gamma_inv\n",
    "                    \n",
    "                    # Get corresponding f values\n",
    "                    f_chunk = np.array(f_list[chunk_start:chunk_end], dtype=np.float64)\n",
    "                    \n",
    "                    # Add to sum\n",
    "                    sum_term += np.dot(weights_chunk, f_chunk)\n",
    "            else:\n",
    "                # For moderate n, compute all weights at once\n",
    "                weights = compute_all_weights(n, alpha, gamma_inv)\n",
    "                f_values = np.array(f_list[:n], dtype=np.float64)\n",
    "                sum_term = np.dot(weights, f_values)\n",
    "        \n",
    "        # Update scale factor\n",
    "        dt_alpha = dt**alpha\n",
    "        a_new = a_start + dt_alpha * sum_term\n",
    "        \n",
    "        # Ensure positivity and check convergence\n",
    "        a_new = max(a_new, 1e-30)\n",
    "        \n",
    "        # Check for significant change\n",
    "        if abs(a_new - a) / max(abs(a), 1e-10) < tolerance and iteration > 10:\n",
    "            # Convergence reached\n",
    "            break\n",
    "        \n",
    "        a = a_new\n",
    "        t += dt\n",
    "        \n",
    "        # Check if we've reached a=1\n",
    "        if not found_present and a >= 1.0:\n",
    "            t_present = t\n",
    "            found_present = True\n",
    "        \n",
    "        # Store f(a) for next iteration\n",
    "        f_list.append(compute_f(a, H0, Omega_m, Omega_r))\n",
    "        \n",
    "        # Store results (thinned)\n",
    "        if iteration % store_every == 0:\n",
    "            # Resize arrays if needed\n",
    "            if store_idx >= len(t_array):\n",
    "                new_capacity = min(len(t_array) * 2, max_iterations // store_every + 10000)\n",
    "                t_array = np.concatenate([\n",
    "                    t_array, \n",
    "                    np.zeros(new_capacity - len(t_array), dtype=np.float64)\n",
    "                ])\n",
    "                a_array = np.concatenate([\n",
    "                    a_array,\n",
    "                    np.zeros(new_capacity - len(a_array), dtype=np.float64)\n",
    "                ])\n",
    "            \n",
    "            t_array[store_idx] = t\n",
    "            a_array[store_idx] = a\n",
    "            store_idx += 1\n",
    "        \n",
    "        # Progress monitoring (optional, for debugging)\n",
    "        if iteration % 10000 == 0:\n",
    "            # Can't print from within Numba, but we can track progress\n",
    "            pass\n",
    "    \n",
    "    # Trim arrays to actual size\n",
    "    t_array = t_array[:store_idx]\n",
    "    a_array = a_array[:store_idx]\n",
    "    \n",
    "    # If never reached a=1, find closest\n",
    "    if not found_present and len(a_array) > 0:\n",
    "        idx_closest = np.argmin(np.abs(a_array - 1.0))\n",
    "        t_present = t_array[idx_closest]\n",
    "    \n",
    "    return t_array, a_array, t_present, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a9e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for quick testing\n",
    "def quick_test(alpha=0.9, iterations=10000):\n",
    "    \"\"\"Quick test of the solver\"\"\"\n",
    "    print(f\"Quick test with α={alpha}, max_iterations={iterations}\")\n",
    "    \n",
    "    t_array, a_array, t_present, actual_iters = solve_fractional_optimized(\n",
    "        alpha=alpha,\n",
    "        max_iterations=iterations,\n",
    "        store_every=10\n",
    "    )\n",
    "    \n",
    "    print(f\"Completed {actual_iters} iterations\")\n",
    "    print(f\"Present time (a=1): {t_present:.4f} H₀⁻¹\")\n",
    "    print(f\"Final a: {a_array[-1]:.6f}\")\n",
    "    print(f\"Time range: {t_array[0]:.2e} to {t_array[-1]:.4f}\")\n",
    "    \n",
    "    return t_array, a_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb49993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test with α=1, max_iterations=10000\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mUntyped global name 'gamma':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'numpy.ufunc'>\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_25864\\3623202651.py\", line 20:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m quick_test(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mquick_test\u001b[1;34m(alpha, iterations)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Quick test of the solver\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuick test with α=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max_iterations=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m t_array, a_array, t_present, actual_iters \u001b[38;5;241m=\u001b[39m solve_fractional_optimized(\n\u001b[0;32m      7\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m      8\u001b[0m     max_iterations\u001b[38;5;241m=\u001b[39miterations,\n\u001b[0;32m      9\u001b[0m     store_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresent time (a=1): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_present\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m H₀⁻¹\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VivoBook\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:423\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    419\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    421\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[1;32m--> 423\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VivoBook\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:364\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mUntyped global name 'gamma':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'numpy.ufunc'>\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_25864\\3623202651.py\", line 20:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "quick_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def solve_fractional_incremental(\n",
    "    alpha=1.0,\n",
    "    H0=1.0,\n",
    "    Omega_m=0.315,\n",
    "    Omega_r=9.2e-5,\n",
    "    a_start=1e-6,\n",
    "    a_end=1.0,\n",
    "    min_dt=1e-12,\n",
    "    max_dt=1e-6,\n",
    "    safety=0.1,\n",
    "    max_iterations=1000000,\n",
    "    store_every=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Version with incremental sum updating to avoid O(N²) complexity.\n",
    "    Uses mathematical recurrence for fractional derivative weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    Omega_de = 1.0 - Omega_m - Omega_r\n",
    "    gamma_inv = 1.0 / gamma(alpha + 1)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    initial_capacity = min(max_iterations // store_every + 1000, 100000)\n",
    "    t_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    a_array = np.zeros(initial_capacity, dtype=np.float64)\n",
    "    \n",
    "    # Initial state\n",
    "    t = 0.0\n",
    "    a = a_start\n",
    "    t_array[0] = t\n",
    "    a_array[0] = a\n",
    "    \n",
    "    # First f(a)\n",
    "    f_current = compute_f(a, H0, Omega_m, Omega_r)\n",
    "    \n",
    "    # We'll maintain the sum Σ w_{j,n} * f_j incrementally\n",
    "    # For fractional derivative, when n → n+1:\n",
    "    # sum_{n+1} = Σ_{j=1}^{n} [(n+2-j)^α - (n+1-j)^α] * f_j + f_{n+1} * γ_inv\n",
    "    \n",
    "    # Store f values (we need history for the incremental update)\n",
    "    f_history = [f_current]\n",
    "    \n",
    "    # Current sum (initialize for n=0)\n",
    "    current_sum = f_current * gamma_inv  # For n=0: sum = f_0 * γ_inv\n",
    "    \n",
    "    store_idx = 1\n",
    "    t_present = -1.0\n",
    "    found_present = False\n",
    "    \n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        if a >= a_end:\n",
    "            break\n",
    "        \n",
    "        # Adaptive time step\n",
    "        dt = exponential_time_scheme(a, H0, Omega_m, Omega_r, t, \n",
    "                                    min_dt, max_dt, safety)\n",
    "        \n",
    "        # Update the sum for new n (n = iteration)\n",
    "        n = iteration  # Current step count (0-based would be iteration-1)\n",
    "        \n",
    "        if n == 1:\n",
    "            # For n=1: sum = [(2)^α - (1)^α] * f_0 + f_1 * γ_inv\n",
    "            new_sum = ((2**alpha - 1**alpha) * gamma_inv) * f_history[0] + \\\n",
    "                     f_current * gamma_inv\n",
    "        else:\n",
    "            # Update sum incrementally:\n",
    "            # sum_{n} = Σ_{j=1}^{n-1} [(n+1-j)^α - (n-j)^α] * f_{j-1} + f_n * γ_inv\n",
    "            \n",
    "            # More efficient: update all weights at once\n",
    "            weights = compute_all_weights(n-1, alpha, gamma_inv)\n",
    "            f_vals = np.array(f_history, dtype=np.float64)\n",
    "            new_sum = np.dot(weights, f_vals)\n",
    "        \n",
    "        current_sum = new_sum\n",
    "        \n",
    "        # Update a\n",
    "        dt_alpha = dt**alpha\n",
    "        a = max(a_start + dt_alpha * current_sum, 1e-30)\n",
    "        t += dt\n",
    "        \n",
    "        # Check present epoch\n",
    "        if not found_present and a >= 1.0:\n",
    "            t_present = t\n",
    "            found_present = True\n",
    "        \n",
    "        # Store new f(a)\n",
    "        f_current = compute_f(a, H0, Omega_m, Omega_r)\n",
    "        f_history.append(f_current)\n",
    "        \n",
    "        # Store results\n",
    "        if iteration % store_every == 0:\n",
    "            if store_idx >= len(t_array):\n",
    "                new_size = min(len(t_array) * 2, max_iterations // store_every + 10000)\n",
    "                t_array = np.concatenate([\n",
    "                    t_array,\n",
    "                    np.zeros(new_size - len(t_array), dtype=np.float64)\n",
    "                ])\n",
    "                a_array = np.concatenate([\n",
    "                    a_array,\n",
    "                    np.zeros(new_size - len(a_array), dtype=np.float64)\n",
    "                ])\n",
    "            \n",
    "            t_array[store_idx] = t\n",
    "            a_array[store_idx] = a\n",
    "            store_idx += 1\n",
    "    \n",
    "    # Trim arrays\n",
    "    t_array = t_array[:store_idx]\n",
    "    a_array = a_array[:store_idx]\n",
    "    \n",
    "    if not found_present and len(a_array) > 0:\n",
    "        idx_closest = np.argmin(np.abs(a_array - 1.0))\n",
    "        t_present = t_array[idx_closest]\n",
    "    \n",
    "    return t_array, a_array, t_present, iteration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
